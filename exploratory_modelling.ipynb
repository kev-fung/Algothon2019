{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exploratory_modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwGCmGeRpQ58",
        "colab_type": "code",
        "outputId": "3c98b018-858e-4968-b15a-c1dfa90a4d90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycm in /usr/local/lib/python3.6/dist-packages (2.5)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pycm) (1.16.5)\n",
            "Requirement already satisfied: art>=1.8 in /usr/local/lib/python3.6/dist-packages (from pycm) (4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.0.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Requirement already satisfied: coverage>=4.1 in /usr/local/lib/python3.6/dist-packages (from art>=1.8->pycm) (4.5.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (41.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (17.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (3.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['random', 'Normalize']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Qf8y3npYem",
        "colab_type": "code",
        "outputId": "5a3109f8-c112-4415-d6e0-f54a2bee63fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset \n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage, RandomResizedCrop, RandomAffine\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyXKI2ZDpj32",
        "colab_type": "text"
      },
      "source": [
        "##Define Train, Validate, Test Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQSlyHFYpc-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()\n",
        "    train_loss, train_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        \n",
        "        train_loss += loss*X.size(0)\n",
        "        train_accuracy += r2_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "  \n",
        "        optimizer.step()\n",
        "        \n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    validation_loss, validation_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            output = model(X)\n",
        "\n",
        "            loss = criterion(output, y)\n",
        "            validation_loss += loss*X.size(0)\n",
        "            validation_accuracy += r2_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "  \n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            \n",
        "            output = model(X)\n",
        "            \n",
        "#             y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiGVmmqhqWpb",
        "colab_type": "text"
      },
      "source": [
        "## Model Development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll59fd_FqWF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class model1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(model1, self).__init__()\n",
        "    self.input = nn.Linear(1,5)\n",
        "    self.linear1 = nn.Linear(5,5)\n",
        "    self.output = nn.Linear(5,1)\n",
        "    self.act = nn.tanh()\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = self.act(self.input(x))\n",
        "    x = self.act(self.linear1(x))\n",
        "    \n",
        "    \n",
        "    x = self.act(self.output(x))\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoJEck3cyXz-",
        "colab_type": "text"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQC5REoVuRuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input data should be [mx1]\n",
        "\n",
        "\n",
        "train_data = \n",
        "validate_data = \n",
        "test_data = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4gQQbl2yb7r",
        "colab_type": "text"
      },
      "source": [
        "## Train and Validate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzn6OptNuPHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(in_model, seed, lr, weight_decay):\n",
        "    model = in_model().to(device)\n",
        "\n",
        "    set_seed(seed)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=weight_decay, amsgrad=False)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    liveloss = PlotLosses()\n",
        "    for epoch in range(n_epochs):\n",
        "        logs = {}\n",
        "        train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "        logs['' + 'log loss'] = train_loss.item()\n",
        "        logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "        validation_loss, validation_accuracy = validate(model, criterion, test_loader)\n",
        "        logs['val_' + 'log loss'] = validation_loss.item()\n",
        "        logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "        liveloss.update(logs)\n",
        "        liveloss.draw()\n",
        "\n",
        "    test_loss, test_acc = validate(model, criterion, test_loader)\n",
        "    print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_acc.item())\n",
        "    print(\"\")\n",
        "\n",
        "# Split data into train and test sets, labels and features\n",
        "# Change the data!!!!\n",
        "X_train, y_train = X_train_orig.astype(float), y_train_orig\n",
        "X_test, y_test = X_test_orig.astype(float), y_test_orig\n",
        "\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n",
        "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test)\n",
        "\n",
        "# mean, std = torch.mean(X_train), torch.std(X_train)\n",
        "\n",
        "# # Assemble tensor datasets\n",
        "# train_ds = CustomImageTensorDataset(X_train, y_train.long(), transform=True, mean=mean, std=std)\n",
        "# test_ds = CustomImageTensorDataset(X_test, y_test.long(), transform=False, mean=mean, std=std)\n",
        "\n",
        "# # Assemble dataloaders\n",
        "# train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "# test_loader = DataLoader(test_ds, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "run(model, seed=42, lr, weight_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}